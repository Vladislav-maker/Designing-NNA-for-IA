# Designing-NNA-for-IA
### Designing neural network architectures for image analysis
---
## Task №1
### Вариант 1
**Цель:** Контроль дисперсии весов.
- Разработайте архитектуру, которая будет за **5 слоев** приводить тензор к размерности `(1, 512, 1, 1)`.
- **Условие:** дисперсия весов третьего слоя должна быть в **два раза больше**, чем у второго и четвертого.
- **Эксперимент:** Проверьте влияние увеличенной дисперсии третьего слоя на распределение активаций после GAP и визуализируйте их гистограмму.

### Вариант 5. Контроль градиентов через глубину
**Цель:** Изучение поведения градиентов в глубокой сети.
- Разработайте сеть с **не менее 6 слоев**, которая выводит тензор `(batch, 64, 8, 8)`.
- **Условие:** Слои должны чередоваться между `Conv2d` и `ReLU`, при этом **градиенты первого слоя должны быть меньше градиентов последнего** после одной итерации `backward()` на случайных данных.
- **Эксперимент:** Визуализируйте градиенты по слоям и объясните, почему градиенты убывают или растут.
---

## Task №2
### Создание и оптимизация ResNet18
### Общая цель
Поэтапная разработка кастомной ResNet18 модели для классификации Tiny ImageNet с анализом влияния различных архитектурных решений на производительность.
**Датасет:** Tiny ImageNet (200 классов) - выберите **10 классов** самостоятельно для работы

### Часть 1: Подготовка данных

### Создание датакласса

Реализуйте собственный класс `TinyImageNetDataset`, наследующий от `torch.utils.data.Dataset`:

- Метод `__init__`: инициализация путей к данным, загрузка списка изображений и меток
- Метод `__len__`: возврат количества примеров в датасете
- Метод `__getitem__`: загрузка и возврат одного примера (изображение + метка)

### Часть 2: Базовая архитектура ResNet18

### 2.1. Реализация Basic Block

Создайте базовый residual блок со следующей структурой:

```
Input
  ↓
Conv2d(kernel_size=3, padding=1, stride=stride)
  ↓
BatchNorm2d
  ↓
ReLU
  ↓
Conv2d(kernel_size=3, padding=1, stride=1)
  ↓
BatchNorm2d
  ↓
  + ← Skip Connection (с возможностью downsample)
  ↓
ReLU
  ↓
Output
```
**Важно:**
- Если входные и выходные размерности не совпадают, используйте skip connection с Conv2d(1x1) + BatchNorm2d
- Первый residual блок может иметь stride=2 для уменьшения пространственного размера

### 2.2. Реализация ResNet18

Создайте архитектуру ResNet18 со следующей структурой:

```
Input (3, 64, 64)
  ↓
Conv2d(3→64, kernel_size=7, stride=2, padding=3)  # или 3x3, stride=1 для Tiny ImageNet
  ↓
BatchNorm2d
  ↓
ReLU
  ↓
MaxPool2d(kernel_size=3, stride=2, padding=1)  # опционально для Tiny ImageNet
  ↓
Layer1: 2x Basic Block (64 channels)
  ↓
Layer2: 2x Basic Block (128 channels, stride=2 в первом блоке)
  ↓
Layer3: 2x Basic Block (256 channels, stride=2 в первом блоке)
  ↓
Layer4: 2x Basic Block (512 channels, stride=2 в первом блоке)  # ОПЦИОНАЛЬНО
  ↓
AdaptiveAvgPool2d(output_size=(1, 1))
  ↓
Flatten
  ↓
Linear(512 → 10)  # 10 классов
  ↓
Output
```

### 2.3. Ограничения для базовой модели:

- **Общее количество параметров:** не более **5 миллионов**
- **Максимальное количество каналов:** до **512**

### 2.4. Скрипт обучения

Реализуйте цикл обучения с следующими компонентами:

**Оптимизатор:**
- Adam или SGD
- Learning rate: 0.001

**Loss function:**
- CrossEntropyLoss

**Метрики:**
- Accuracy для train/validation
- Loss для train/validation

**Обучение:**
- Количество эпох: 20-30
- Логирование метрик на каждой эпохе

### 2.5: Визуализация базовых результатов

После обучения базовой модели создайте:

1. **График Accuracy:**
   - X: эпохи
   - Y: accuracy
   - Две линии: train и validation

2. **График Loss:**
   - X: эпохи
   - Y: loss
   - Две линии: train и validation

3. **Информация о модели:**
   - Общее количество параметров
   - Архитектура (выведите через print(model))


### Часть 3: Поэтапная оптимизация модели

### 3.1: Оптимизация количества каналов

**Цель:** Изучение влияния количества каналов на производительность.

**Эксперимент:**
- Создайте 2 варианта модели:
  - **Вариант A:** 32 → 64 → 128 → 256 каналов
  - **Вариант B:** 64 → 128 → 256 каналов (без 4-го слоя)
- Обучите обе модели с теми же гиперпараметрами
- Сравните:
  - Количество параметров
  - Validation accuracy

**Результат:**
- Таблица сравнения
- Графики accuracy и loss для обоих вариантов
- Вывод: какая конфигурация лучше?

### 3.2: Эксперименты с количеством residual блоков

**Цель:** Изучение влияния глубины сети (количества residual блоков) на производительность.

**Эксперимент:**
- Используйте лучшую конфигурацию каналов из Этапа 3.1
- Создайте 3 варианта модели с разным количеством блоков в каждом слое:
  - **Вариант A:** [1, 1, 1, 1] - по 1 блоку в каждом слое (мелкая сеть)
  - **Вариант B:** [2, 2, 2, 2] - по 2 блока в каждом слое (стандартная ResNet18)
  - **Вариант C:** [3, 3, 3, 3] - по 3 блока в каждом слое (глубокая сеть)
- Обучите все три модели с одинаковыми гиперпараметрами

**Архитектура вариантов:**
```
Вариант A (4 блока):  Layer1[1 блок] → Layer2[1 блок] → Layer3[1 блок] → Layer4[1 блок]
Вариант B (8 блоков): Layer1[2 блока] → Layer2[2 блока] → Layer3[2 блока] → Layer4[2 блока]
Вариант C (12 блоков): Layer1[3 блока] → Layer2[3 блока] → Layer3[3 блока] → Layer4[3 блока]
```

**Результат:**
- Сравните:
  - Количество параметров
  - Validation accuracy
  - Скорость сходимости (на каких эпохах модель достигает лучших результатов)
- Графики accuracy для всех трех вариантов на одном графике
- Анализ: какая глубина оптимальна? Есть ли переобучение у более глубоких моделей?
- Вывод: какое количество блоков работает лучше?

### 3.3: Эксперименты с функциями активации

**Цель:** Исследование влияния различных активаций на обучение.

**Модификация модели:**
Замените ReLU на другие функции активации:

**Эксперимент:**
- Используйте лучшую конфигурацию из Этапа 3.2 (каналы + количество блоков)
- Обучите модели с разными активациями:
  - **Вариант A:** ReLU (baseline)
  - **Вариант B:** LeakyReLU
  - **Вариант C:** ELU
  - **Вариант D:** GELU

**Важно:** Используйте `inplace=True` где возможно для экономии памяти

**Результат:**
- Сравнение скорости сходимости (accuracy на каждой эпохе)
- Финальная validation accuracy
- Вывод: какая активация работает лучше?


### Часть 4: Финальная модель и тестирование

### 4.1: Создание финальной модели

На основе всех экспериментов:
- Выберите лучшую конфигурацию каналов (из Этапа 3.1)
- Выберите оптимальное количество residual блоков (из Этапа 3.2) - объясните, почему выбрали именно это количество
- Выберите лучшую функцию активации (из Этапа 3.3)
- Обучите финальную модель на 30-40 эпох с выбранными параметрами

**Дополнительно (опционально):**
- Добавьте data augmentation
- Попробуйте другие оптимизаторы (AdamW как вариант)

### 4.2: Тестирование на test set

После обучения финальной модели:

1. **Загрузите лучшую модель** (сохраненную по validation accuracy)
2. **Оцените на test set:**
   - Accuracy
   - Precision, Recall, F1-score для каждого класса
   - Confusion Matrix

### 4.3: Визуальный анализ

Создайте визуализацию с 10 случайными примерами из test set:

```
[Изображение 1] | Истинный класс: cat    | Предсказание: cat
[Изображение 2] | Истинный класс: dog    | Предсказание: wolf
...
```

### 4.4: Сравнительная таблица всех экспериментов

Создайте итоговую таблицу со всеми результатами:

| Этап | Конфигурация | Параметры | Val Accuracy | Train Accuracy |
|------|--------------|-----------|--------------|----------------|
| **Baseline** | Ваша базовая модель | X.XM | XX.X% | XX.X% |
| **3.1-A** | 32→64→128→256 | X.XM | XX.X% | XX.X% |
| **3.1-B** | 64→128→256 | X.XM | XX.X% | XX.X% |
| **3.2-A** | [1,1,1,1] блоков | X.XM | XX.X% | XX.X% |
| **3.2-B** | [2,2,2,2] блоков | X.XM | XX.X% | XX.X% |
| **3.2-C** | [3,3,3,3] блоков | X.XM | XX.X% | XX.X% |
| **3.3-A** | ReLU | X.XM | XX.X% | XX.X% |
| **3.3-B** | LeakyReLU | X.XM | XX.X% | XX.X% |
| **3.3-C** | ELU | X.XM | XX.X% | XX.X% |
| **3.3-D** | GELU | X.XM | XX.X% | XX.X% |
| **Final** | Лучшая конфигурация | X.XM | XX.X% | XX.X% |

**Анализ:**
- Какая конфигурация показала лучший результат?
- Есть ли признаки переобучения (большая разница между train и val)?
---
## Task №3
Классификация 128x128 + U-Net c бэкбоном

### Датасеты
- Классификация: Tiny ImageNet-200 из семинара 2.
  - Набор данных необходимо взять из второго семинара и привести к разрешению 128x128
  - Разрешение: приведите вход к 128×128 (ресайз/кроп по вашему выбору, главное — корректно описать в отчёте).
- Сегментация: MOON_SEGMENTATION_BINARY из семинара 3.
  - Структура: `images/render/*.png` — входы, `images/ground/*.png` — бинарные маски.

### Часть 1. Классификатор 128×128
- Требования к модели:
  - Своя архитектура (разрешается вдохновляться CNN-идеями: Conv-BN-ReLU, блоки с даунсемплингом, GAP и т.д.).
  - Ограничение на параметризованность: не более ~5M параметров.
  - Вход: 128×128×3.
  - Можно выбрать любое количество классов для обучения!
- Обучение:
  - Трен/вал сплит: выберите собственную стратификацию.
  - Аугментации: разумные (кроп, флипы, color jitter и т.д.), кратко опишите в отчёте.
- Что сдаём по части 1:
  - График/лог обучения (loss/accuracy по эпохам) и итоговые метрики на валидации.
  - Чекпоинт модели (по возможности) или веса/ссылка.

### Часть 2. Базовая U-Net на "Луне"
- Требования к архитектуре U-Net (зафиксируйте и опишите в отчёте):
  - Глубина: 4 уровня down/4 up (энкодер-декодер с skip-связями).
  - Базовые каналы на первом уровне: 32 или 64 (по желанию можно выбрать свое количество каналов, но надо будет объяснить).
  - Даунсемплинг: stride 2 или MaxPool.
  - Итоговый слой: 1 канал с сигмоидой (бинарная сегментация).
  - Ограничение на количество параметров: до ~2.5M (рекомендуется укладываться, но допускается ±10%).
  - Вход: 128×128×3.
- Обучение:
  - Лосс: BCEWithLogitsLoss или Dice Loss, допустимо комбинировать (например, 0.5*BCE + 0.5*Dice).
  - Метрики для мониторинга: IoU (Jaccard), Dice, Pixel Accuracy.
  - Аугментации: горизонтальные/вертикальные флипы, лёгкие геометрические и цветовые — по желанию (можно добавлять другие).
- Что сдаём по части 2:
  - Логи обучения и итоговые метрики на валидации: IoU, Dice, Pixel Acc.
  - 3–5 визуализаций: вход, предсказанная маска, GT маска.

### Часть 3. U-Net с бэкбоном из классификатора
- Идея: использовать энкодер из вашей модели классификации как бэкбон U‑Net.
  - Вариант A (заморозка): заморозить веса энкодера, обучать только декодер.
  - Вариант B (тонкая настройка): полностью разморозить энкодер на поздних этапах.
  - Если у классификатора есть GAP/FC-голова — удалите её; возьмите сверточные блоки до глобального усреднения как энкодерные стадии.
- Ограничения и замечания:
  - Если количество стадий не совпадает, добавьте адаптационные 1×1 свёртки и интерполяции/пулинг, но опишите это.
- Обучение:
  - Тот же датасет "луна", те же метрики.
  - Сравните результаты с базовой U‑Net из части 2 (таблица метрик).
- Что сдаём по части 3:
  - Метрики и сравнение с базовой U‑Net (желательно таблица).
